{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 285 Assignment 1: Linear Regression\n",
    "\n",
    "For this part of assignment, you are tasked to implement a linear regression algorithm for multiclass classification and test it on the CIFAR10 dataset.\n",
    "\n",
    "You sould run the whole notebook and answer the questions in the notebook.\n",
    "\n",
    "CIFAR 10 dataset contains 32x32x3 RGB images of 10 distinct cateogaries, and our aim is to predict which class the image belongs to\n",
    "\n",
    "TO SUBMIT: PDF of this notebook with all the required outputs and answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ece285.utils.data_processing import get_cifar10_data\n",
    "\n",
    "# Use a subset of CIFAR10 for the assignment\n",
    "dataset = get_cifar10_data(\n",
    "    subset_train=5000,\n",
    "    subset_val=250,\n",
    "    subset_test=500,\n",
    ")\n",
    "\n",
    "print(dataset.keys())\n",
    "print(\"Training Set Data  Shape: \", dataset[\"x_train\"].shape)\n",
    "print(\"Training Set Label Shape: \", dataset[\"y_train\"].shape)\n",
    "print(\"Validation Set Data  Shape: \", dataset[\"x_val\"].shape)\n",
    "print(\"Validation Set Label Shape: \", dataset[\"y_val\"].shape)\n",
    "print(\"Test Set Data  Shape: \", dataset[\"x_test\"].shape)\n",
    "print(\"Test Set Label Shape: \", dataset[\"y_test\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_val = dataset[\"x_val\"]\n",
    "y_val = dataset[\"y_val\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = [\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "samples_per_class = 7\n",
    "\n",
    "\n",
    "def visualize_data(dataset, classes, samples_per_class):\n",
    "    num_classes = len(classes)\n",
    "    for y, cls in enumerate(classes):\n",
    "        idxs = np.flatnonzero(y_train == y)\n",
    "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "        for i, idx in enumerate(idxs):\n",
    "            plt_idx = i * num_classes + y + 1\n",
    "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "            plt.imshow(dataset[idx])\n",
    "            plt.axis(\"off\")\n",
    "            if i == 0:\n",
    "                plt.title(cls)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_data(\n",
    "    x_train.reshape(5000, 3, 32, 32).transpose(0, 2, 3, 1), classes, samples_per_class\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression for multi-class classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Linear Regression Algorithm has 2 hyperparameters that you can experiment with:\n",
    "\n",
    "- **Learning rate** - controls how much we change the current weights of the classifier during each update. We set it at a default value of 0.5, and later you are asked to experiment with different values. We recommend looking at the graphs and observing how the performance of the classifier changes with different learning rate.\n",
    "- **Number of Epochs** - An epoch is a complete iterative pass over all of the data in the dataset. During an epoch we predict a label using the classifier and then update the weights of the classifier according the linear classifier update rule for each sample in the training set. We evaluate our models after every 10 epochs and save the accuracies, which are later used to plot the training, validation and test VS epoch curves.\n",
    "- **Weight Decay** - Regularization can be used to constrain the weights of the classifier and prevent their values from blowing up. Regularization helps in combatting overfitting. You will be using the 'weight_decay' term to introduce regularization in the classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation (50%)\n",
    "\n",
    "You first need to implement the Linear Regression method in `algorithms/linear_regression.py`. You need to fill in the training function as well as the prediction function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the algorithm implementation (TODO: Complete the Linear Regression in algorithms/linear_regression.py)\n",
    "from ece285.algorithms import Linear\n",
    "from ece285.utils.evaluation import get_classification_accuracy\n",
    "\n",
    "num_classes = 10  # Cifar10 dataset has 10 different classes\n",
    "\n",
    "# Initialize hyper-parameters\n",
    "learning_rate = 0.0001  # You will be later asked to experiment with different learning rates and report results\n",
    "num_epochs_total = 1000  # Total number of epochs to train the classifier\n",
    "epochs_per_evaluation = 10  # Epochs per step of evaluation; We will evaluate our model regularly during training\n",
    "N, D = dataset[\n",
    "    \"x_train\"\n",
    "].shape  # Get training data shape, N: Number of examples, D:Dimensionality of the data\n",
    "weight_decay = 0.0\n",
    "\n",
    "# Insert additional scalar term 1 in the samples to account for the bias as discussed in class\n",
    "x_train = np.insert(x_train, D, values=1, axis=1)\n",
    "x_val = np.insert(x_val, D, values=1, axis=1)\n",
    "x_test = np.insert(x_test, D, values=1, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation function -> Outputs accuracy data\n",
    "def train(learning_rate_, weight_decay_):\n",
    "    # Create a linear regression object\n",
    "    linear_regression = Linear(\n",
    "        num_classes, learning_rate_, epochs_per_evaluation, weight_decay_\n",
    "    )\n",
    "\n",
    "    # Randomly initialize the weights and biases\n",
    "    weights = np.random.randn(num_classes, D + 1) * 0.0001\n",
    "\n",
    "    train_accuracies, val_accuracies, test_accuracies = [], [], []\n",
    "\n",
    "    # Train the classifier\n",
    "    for _ in range(int(num_epochs_total / epochs_per_evaluation)):\n",
    "        # Train the classifier on the training data\n",
    "        weights = linear_regression.train(x_train, y_train, weights)\n",
    "\n",
    "        # Evaluate the trained classifier on the training dataset\n",
    "        y_pred_train = linear_regression.predict(x_train)\n",
    "        train_accuracies.append(get_classification_accuracy(y_pred_train, y_train))\n",
    "\n",
    "        # Evaluate the trained classifier on the validation dataset\n",
    "        y_pred_val = linear_regression.predict(x_val)\n",
    "        val_accuracies.append(get_classification_accuracy(y_pred_val, y_val))\n",
    "\n",
    "        # Evaluate the trained classifier on the test dataset\n",
    "        y_pred_test = linear_regression.predict(x_test)\n",
    "        test_accuracies.append(get_classification_accuracy(y_pred_test, y_test))\n",
    "\n",
    "    return train_accuracies, val_accuracies, test_accuracies, weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Accuracies vs epoch graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_accuracies(train_acc, val_acc, test_acc):\n",
    "    # Plot Accuracies vs Epochs graph for all the three\n",
    "    epochs = np.arange(0, int(num_epochs_total / epochs_per_evaluation))\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch/10\")\n",
    "    plt.plot(epochs, train_acc, epochs, val_acc, epochs, test_acc)\n",
    "    plt.legend([\"Training\", \"Validation\", \"Testing\"])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training and plotting for default parameter values as mentioned above\n",
    "t_ac, v_ac, te_ac, weights = train(learning_rate, weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(t_ac, v_ac, te_ac)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different learning rates and plot graphs for all (20%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the best values\n",
    "best_weights = weights\n",
    "best_learning_rate = learning_rate\n",
    "best_weight_decay = weight_decay\n",
    "\n",
    "# TODO\n",
    "# Repeat the above training and evaluation steps for the following learning rates and plot graphs\n",
    "# You need to try 3 learning rates and submit all 3 graphs along with this notebook pdf to show your learning rate experiments\n",
    "learning_rates = []\n",
    "weight_decay = 0.0  # No regularization for now\n",
    "\n",
    "# FEEL FREE TO EXPERIMENT WITH OTHER VALUES. REPORT OTHER VALUES IF THEY ACHIEVE A BETTER PERFORMANCE\n",
    "\n",
    "# for lr in learning_rates: Train the classifier and plot data\n",
    "# Step 1. train_accu, val_accu, test_accu = train(lr, weight_decay)\n",
    "# Step 2. plot_accuracies(train_accu, val_accu, test_accu)\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    # TODO: Train the classifier with different learning rates and plot\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inline Question 1.\n",
    "\n",
    "Which one of these learning rates (best_lr) would you pick to train your model? Please Explain why.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization: Try different weight decay and plot graphs for all (20%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a non-zero weight_decay (Regularization constant) term and repeat the training and evaluation\n",
    "# Use the best learning rate as obtained from the above exercise, best_lr\n",
    "\n",
    "# You need to try 3 learning rates and submit all 3 graphs along with this notebook pdf to show your weight decay experiments\n",
    "weight_decays = []\n",
    "\n",
    "# FEEL FREE TO EXPERIMENT WITH OTHER VALUES. REPORT OTHER VALUES IF THEY ACHIEVE A BETTER PERFORMANCE\n",
    "\n",
    "# for weight_decay in weight_decays: Train the classifier and plot data\n",
    "# Step 1. train_accu, val_accu, test_accu = train(best_lr, weight_decay)\n",
    "# Step 2. plot_accuracies(train_accu, val_accu, test_accu)\n",
    "\n",
    "for weight_decay in weight_decays:\n",
    "    # TODO: Train the classifier with different weighty decay and plot\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inline Question 2.\n",
    "\n",
    "Discuss underfitting and overfitting as observed in the 5 graphs obtained by changing the regularization.\n",
    "Which weight_decay term gave you the best classifier performance?\n",
    "HINT: Do not just think in terms of best training set performance, keep in mind that the real utility of a machine learning model is when it performs well on data it has never seen before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the filters (10%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These visualizations will only somewhat make sense if your learning rate and weight_decay parameters were\n",
    "# properly chosen in the model. Do your best.\n",
    "\n",
    "# TODO: Run this cell and Show filter visualizations for the best set of weights you obtain.\n",
    "# Report the 2 hyperparameters you used to obtain the best model.\n",
    "\n",
    "# NOTE: You need to set `best_learning_rate` and `best_weight_decay` to the values that gave the highest accuracy\n",
    "print(\"Best LR:\", best_learning_rate)\n",
    "print(\"Best Weight Decay:\", best_weight_decay)\n",
    "\n",
    "# NOTE: You need to set `best_weights` to the weights with the highest accuracy\n",
    "w = best_weights[:, :-1]\n",
    "w = w.reshape(10, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "classes = [\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "for i in range(10):\n",
    "    fig.add_subplot(2, 5, i + 1)\n",
    "\n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[i, :, :, :].squeeze() - w_min) / (w_max - w_min)\n",
    "    # plt.imshow(wimg.astype('uint8'))\n",
    "    plt.imshow(wimg.astype(int))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(classes[i])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
